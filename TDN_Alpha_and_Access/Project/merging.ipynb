{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2ef74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Load Excel workbook\n",
    "file_path = r'C:\\Users\\user\\Desktop\\Data_Analyst\\TDN_Network\\TDN_Alpha_and_Access\\AI_Showcase_Virtual_Conf_Full_attendee_list.xlsx'\n",
    "excel_file = pd.ExcelFile(file_path)\n",
    "all_sheets = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# Extract relevant sheets\n",
    "df_attendees = all_sheets['Full list of attendees']\n",
    "df_companies = all_sheets['Companies seeking AI automation']\n",
    "df_freelancers = all_sheets['AI freelancers & agencies for a']\n",
    "df_investors = all_sheets['AI investors']\n",
    "df_startups = all_sheets['AI startups']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff264e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2440\\1067880734.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([df_attendees, df_companies, df_freelancers, df_investors, df_startups], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Dataset Shape: (3856, 96)\n"
     ]
    }
   ],
   "source": [
    "# Add Source Column to each DataFrame\n",
    "df_attendees['Source'] = 'Attendees'\n",
    "df_companies['Source'] = 'Companies'\n",
    "df_freelancers['Source'] = 'Freelancers'\n",
    "df_investors['Source'] = 'Investors'\n",
    "df_startups['Source'] = 'Startups'\n",
    "\n",
    "# Identify all possible columns\n",
    "all_columns = set(df_attendees.columns) | set(df_companies.columns) | set(df_freelancers.columns) | set(df_investors.columns) | set(df_startups.columns)\n",
    "\n",
    "# Align columns across all DataFrames (add missing columns with NaN)\n",
    "def align_columns(df, all_columns):\n",
    "    missing_cols = all_columns - set(df.columns)\n",
    "    for col in missing_cols:\n",
    "        df[col] = pd.NA\n",
    "    return df[list(all_columns)]  # Ensure same column order\n",
    "\n",
    "df_attendees = align_columns(df_attendees, all_columns)\n",
    "df_companies = align_columns(df_companies, all_columns)\n",
    "df_freelancers = align_columns(df_freelancers, all_columns)\n",
    "df_investors = align_columns(df_investors, all_columns)\n",
    "df_startups = align_columns(df_startups, all_columns)\n",
    "\n",
    "# Combine all into one DataFrame\n",
    "combined_df = pd.concat([df_attendees, df_companies, df_freelancers, df_investors, df_startups], ignore_index=True)\n",
    "\n",
    "# Final Combined Dataset\n",
    "print(f\"Combined Dataset Shape: {combined_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97964543",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_excel('Cleaned_Data/Master_Combined_List.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "014832cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Standardize & Rename Important Columns ---\n",
    "df = combined_df \n",
    "\n",
    "# Clean column names globally\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "               .str.replace(r'\\n', ' ', regex=True)  # Remove line breaks\n",
    "               .str.replace(r'\\s+\\(\\d+\\)', '', regex=True)  # Remove counts like (655)\n",
    "               .str.replace(r'\\s+', ' ', regex=True)  # Normalize multiple spaces to single\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0574af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_rename(col_name):\n",
    "    # --- Priority 1: Exact Matches ---\n",
    "    if 'Name' in col_name and 'Company' not in col_name:\n",
    "        return 'Name'\n",
    "    elif 'LinkedIn' in col_name:\n",
    "        return 'LinkedIn'\n",
    "    elif 'Company Name' in col_name:\n",
    "        return 'Company'\n",
    "    elif 'Website' in col_name:\n",
    "        return 'Website'\n",
    "\n",
    "    # --- Priority 2: Needs Classification ---\n",
    "    elif 'Interested in AI automation services' in col_name:\n",
    "        return 'Wants_Automation'\n",
    "    elif 'Interested in educating their team' in col_name:\n",
    "        return 'Wants_Team_Training'\n",
    "    elif 'Interested in taking an AI automation course' in col_name:\n",
    "        return 'Wants_Personal_Course'\n",
    "\n",
    "    # --- Priority 3: Investment Stage ---\n",
    "    elif 'Pre-seed' in col_name:\n",
    "        return 'Invest_PreSeed'\n",
    "    elif 'Seed Startups' in col_name:\n",
    "        return 'Invest_Seed'\n",
    "    elif 'Series A' in col_name:\n",
    "        return 'Invest_SeriesA'\n",
    "    elif 'Series B' in col_name:\n",
    "        return 'Invest_SeriesB'\n",
    "    elif 'Series C+' in col_name:\n",
    "        return 'Invest_SeriesC'\n",
    "\n",
    "    # --- Priority 4: Regions ---\n",
    "    elif 'US' in col_name:\n",
    "        return 'Region_US'\n",
    "    elif 'Europe' in col_name:\n",
    "        return 'Region_Europe'\n",
    "    elif 'Africa' in col_name:\n",
    "        return 'Region_Africa'\n",
    "    elif 'Asia Pacific' in col_name:\n",
    "        return 'Region_AsiaPacific'\n",
    "    elif 'Middle East' in col_name:\n",
    "        return 'Region_MiddleEast'\n",
    "    elif 'Latin America' in col_name:\n",
    "        return 'Region_LatinAmerica'\n",
    "    elif 'Israel' in col_name:\n",
    "        return 'Region_Israel'\n",
    "    elif 'Canada' in col_name:\n",
    "        return 'Region_Canada'\n",
    "    elif 'UK' in col_name:\n",
    "        return 'Region_UK'\n",
    "\n",
    "    # --- Default: Return Original ---\n",
    "    return col_name\n",
    "\n",
    "# Apply Smart Renaming to Columns\n",
    "df = df.rename(columns=lambda x: smart_rename(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "823f8b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Globally – everywhere', 'Seed', 'Region_Europe', 'Website', 'Invest_PreSeed', 'LinkedIn', 'Region_US', 'Region_Africa', 'Region_LatinAmerica', 'WhatsApp Number', 'Company', 'Wants_Personal_Course', 'Region_US', 'Wants_Personal_Course', 'Region_Israel', 'Region_AsiaPacific', 'Region_Africa', 'Invest_SeriesB', 'Region_AsiaPacific', 'Region_MiddleEast', 'Region_Europe', 'Wants_Automation', 'AI freelancers & agencies', 'Raising Globally', 'Bootstrapped', 'Region_Israel', 'Wants_Personal_Course', 'Globally – everywhere', 'Company Headcount', 'Region_Canada', 'Region_Israel', 'Invest_SeriesA', 'Invest_Seed', 'Invest_SeriesC', 'Business owner / CEO / Director', 'Region_Canada', 'Region_Israel', 'Invest_PreSeed', 'AI tools used to automate client processes', 'Region_Europe', 'Region_Africa', 'Invest_SeriesB', 'Region_AsiaPacific', 'General attendees', 'AI startups', 'Wants_Team_Training', 'Wants_Team_Training', 'Region_Canada', 'Region_Africa', 'Wants_Automation', 'Invest_SeriesA', 'Seed Stage Startup', 'Invest_SeriesA', 'Check size', 'Region_LatinAmerica', 'Region_UK', 'Region_MiddleEast', 'Invest_Seed', 'Region_MiddleEast', 'Pricing: hourly rate and/or typical project cost engagement (min & max)', 'Wants_Automation', 'Wants_Team_Training', 'Wants_Personal_Course', 'Wants_Automation', 'Invest_SeriesC', 'Region_US', 'Invest_SeriesC', 'Region_AsiaPacific', 'Other regions', 'Wants_Team_Training', 'Name', 'Region_US', 'Region_MiddleEast', 'AI investors', 'Email', 'Region_Canada', 'Globally – everywhere', 'Processes looking to be automated with AI', 'Region_Europe', 'Invest_SeriesB', 'Region_LatinAmerica', 'Bootstrapped Startup', 'Region_UK', 'Region_UK', 'Other regions .1', 'Invest_PreSeed', 'Invest_SeriesC', 'Invest_SeriesA', 'Wants_Team_Training', 'Invest_SeriesB', 'Region_LatinAmerica', 'Source', 'Wants_Personal_Course', 'Invest_PreSeed', 'Region_UK', 'Wants_Automation']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b63c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2440\\2436564540.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df[col] = df[col].apply(clean_flag)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Clean Boolean Flags Robustly ---\n",
    "def clean_flag(x):\n",
    "    \"\"\"\n",
    "    Converts various formats into True/False.\n",
    "    Handles scalar, list, Series, and malformed entries gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(x, (list, pd.Series)):\n",
    "            x = next((i for i in x if pd.notnull(i)), None)\n",
    "\n",
    "        if pd.isna(x):\n",
    "            return False\n",
    "        if isinstance(x, str):\n",
    "            x_clean = x.strip().lower()\n",
    "            return x_clean in ['1', 'true', 'yes']\n",
    "        return bool(x)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Cleaning Flag Value: {x} — {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Step 2: Define Column Groups ---\n",
    "core_columns = ['Name', 'LinkedIn', 'Company', 'Website']\n",
    "need_columns = ['Wants_Automation', 'Wants_Team_Training', 'Wants_Personal_Course']\n",
    "invest_columns = ['Invest_PreSeed', 'Invest_Seed', 'Invest_SeriesA', 'Invest_SeriesB', 'Invest_SeriesC']\n",
    "region_columns = ['Region_US', 'Region_Europe', 'Region_Africa', 'Region_AsiaPacific', \n",
    "                  'Region_MiddleEast', 'Region_LatinAmerica', 'Region_Israel', \n",
    "                  'Region_Canada', 'Region_UK']\n",
    "\n",
    "# --- Step 3: Clean Flags Across All Groups ---\n",
    "for col in need_columns + invest_columns + region_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_flag)\n",
    "    else:\n",
    "        print(f\"[WARNING] Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "# --- Step 4: Filter Data to Relevant Columns ---\n",
    "available_columns = [col for col in core_columns + need_columns + invest_columns + region_columns if col in df.columns]\n",
    "cleaned_df = df[available_columns].copy()\n",
    "\n",
    "# --- Step 5: Summarize AI Needs, Investment Interests & Regions ---\n",
    "def summarize_needs(row):\n",
    "    needs = []\n",
    "    if row.get('Wants_Automation'): needs.append('Automation Service')\n",
    "    if row.get('Wants_Team_Training'): needs.append('Team Training')\n",
    "    if row.get('Wants_Personal_Course'): needs.append('Personal Course')\n",
    "    return ', '.join(needs) if needs else 'No AI Need'\n",
    "\n",
    "def summarize_investments(row):\n",
    "    levels = []\n",
    "    if row.get('Invest_PreSeed'): levels.append('Pre-Seed')\n",
    "    if row.get('Invest_Seed'): levels.append('Seed')\n",
    "    if row.get('Invest_SeriesA'): levels.append('Series A')\n",
    "    if row.get('Invest_SeriesB'): levels.append('Series B')\n",
    "    if row.get('Invest_SeriesC'): levels.append('Series C+')\n",
    "    return ', '.join(levels) if levels else 'No Investment Interest'\n",
    "\n",
    "def summarize_regions(row):\n",
    "    regions = []\n",
    "    for region_col in region_columns:\n",
    "        if row.get(region_col):\n",
    "            regions.append(region_col.replace('Region_', '').replace('_', ' '))\n",
    "    return ', '.join(regions) if regions else 'No Regional Focus'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c143b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name LinkedIn                                            Company  \\\n",
      "0  🚀 Tyler Kelley      NaN                        SLAM + Outsourced Marketing   \n",
      "1          A Amin      NaN                                 Operations manager   \n",
      "2             A D      NaN                                   Edit on the Spot   \n",
      "3        a data 0      NaN                                               Self   \n",
      "4           A.D R      NaN  I am transforming as AI consultant my clients ...   \n",
      "\n",
      "                    Website  Wants_Automation  Wants_Automation  \\\n",
      "0            slamagency.com              True             False   \n",
      "1                        na              True             False   \n",
      "2                       NaN              True             False   \n",
      "3                       NaN              True             False   \n",
      "4  Will be re-launched soon              True             False   \n",
      "\n",
      "   Wants_Automation  Wants_Automation  Wants_Automation  Wants_Team_Training  \\\n",
      "0             False              True             False                False   \n",
      "1             False              True             False                False   \n",
      "2             False              True             False                False   \n",
      "3             False              True             False                False   \n",
      "4             False              True             False                False   \n",
      "\n",
      "   ...  Region_Canada  Region_Canada  Region_Canada  Region_UK  Region_UK  \\\n",
      "0  ...          False          False          False      False      False   \n",
      "1  ...          False          False          False      False      False   \n",
      "2  ...          False          False          False      False      False   \n",
      "3  ...          False          False          False      False      False   \n",
      "4  ...          False          False          False      False      False   \n",
      "\n",
      "   Region_UK  Region_UK                      AI_Need_Summary  \\\n",
      "0      False      False  Automation Service, Personal Course   \n",
      "1      False      False  Automation Service, Personal Course   \n",
      "2      False      False  Automation Service, Personal Course   \n",
      "3      False      False  Automation Service, Personal Course   \n",
      "4      False      False  Automation Service, Personal Course   \n",
      "\n",
      "   Investment_Interest  Region_Focus  \n",
      "0             Series B    MiddleEast  \n",
      "1             Series B    MiddleEast  \n",
      "2             Series B    MiddleEast  \n",
      "3             Series B    MiddleEast  \n",
      "4             Series B    MiddleEast  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Safe Getter to Avoid Series Issues ---\n",
    "def get_scalar(row, col_name):\n",
    "    try:\n",
    "        val = row.get(col_name, False)\n",
    "        if isinstance(val, (pd.Series, list)):\n",
    "            val = next((v for v in val if pd.notna(v)), False)\n",
    "        return bool(val)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Getting Scalar for {col_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Updated Summary Functions ---\n",
    "def summarize_needs(row):\n",
    "    needs = []\n",
    "    if get_scalar(row, 'Wants_Automation'): needs.append('Automation Service')\n",
    "    if get_scalar(row, 'Wants_Team_Training'): needs.append('Team Training')\n",
    "    if get_scalar(row, 'Wants_Personal_Course'): needs.append('Personal Course')\n",
    "    return ', '.join(needs) if needs else 'No AI Need'\n",
    "\n",
    "def summarize_investments(row):\n",
    "    levels = []\n",
    "    if get_scalar(row, 'Invest_PreSeed'): levels.append('Pre-Seed')\n",
    "    if get_scalar(row, 'Invest_Seed'): levels.append('Seed')\n",
    "    if get_scalar(row, 'Invest_SeriesA'): levels.append('Series A')\n",
    "    if get_scalar(row, 'Invest_SeriesB'): levels.append('Series B')\n",
    "    if get_scalar(row, 'Invest_SeriesC'): levels.append('Series C+')\n",
    "    return ', '.join(levels) if levels else 'No Investment Interest'\n",
    "\n",
    "def summarize_regions(row):\n",
    "    regions = []\n",
    "    for region_col in region_columns:\n",
    "        if get_scalar(row, region_col):\n",
    "            regions.append(region_col.replace('Region_', '').replace('_', ' '))\n",
    "    return ', '.join(regions) if regions else 'No Regional Focus'\n",
    "\n",
    "# --- Apply Summary Columns Again ---\n",
    "cleaned_df['AI_Need_Summary'] = cleaned_df.apply(summarize_needs, axis=1)\n",
    "cleaned_df['Investment_Interest'] = cleaned_df.apply(summarize_investments, axis=1)\n",
    "cleaned_df['Region_Focus'] = cleaned_df.apply(summarize_regions, axis=1)\n",
    "\n",
    "# --- Final Output ---\n",
    "print(cleaned_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c7ad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                      0\n",
       "LinkedIn               2920\n",
       "Company                  75\n",
       "Website                1725\n",
       "Wants_Automation          0\n",
       "                       ... \n",
       "Region_UK                 0\n",
       "Region_UK                 0\n",
       "AI_Need_Summary           0\n",
       "Investment_Interest       0\n",
       "Region_Focus              0\n",
       "Length: 76, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5e05ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name    LinkedIn  \\\n",
      "0  🚀 Tyler Kelley  Not Listed   \n",
      "1          A Amin  Not Listed   \n",
      "2             A D  Not Listed   \n",
      "3        a data 0  Not Listed   \n",
      "4           A.D R  Not Listed   \n",
      "\n",
      "                                             Company                   Website  \n",
      "0                        SLAM + Outsourced Marketing            slamagency.com  \n",
      "1                                 Operations manager                        na  \n",
      "2                                   Edit on the Spot                Not Listed  \n",
      "3                                               Self                Not Listed  \n",
      "4  I am transforming as AI consultant my clients ...  Will be re-launched soon  \n"
     ]
    }
   ],
   "source": [
    "# --- Columns to Fill ---\n",
    "columns_to_fill = ['Name', 'LinkedIn', 'Company', 'Website']\n",
    "\n",
    "# --- Ensure columns_to_fill exist in df (handles duplicates by selecting all matching columns) ---\n",
    "existing_cols = [col for col in cleaned_df.columns if any(col.startswith(target) for target in columns_to_fill)]\n",
    "\n",
    "# --- Replace NaNs in these columns with 'Not Listed' ---\n",
    "cleaned_df[existing_cols] = cleaned_df[existing_cols].fillna('Not Listed')\n",
    "\n",
    "# --- Verify ---\n",
    "print(cleaned_df[existing_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d86699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate Column Names by appending .1, .2 if duplicated\n",
    "def deduplicate_columns(columns):\n",
    "    counts = {}\n",
    "    new_columns = []\n",
    "    for col in columns:\n",
    "        if col in counts:\n",
    "            counts[col] += 1\n",
    "            new_columns.append(f\"{col}.{counts[col]}\")\n",
    "        else:\n",
    "            counts[col] = 0\n",
    "            new_columns.append(col)\n",
    "    return new_columns\n",
    "\n",
    "# Apply deduplication to cleaned_df columns\n",
    "cleaned_df.columns = deduplicate_columns(cleaned_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06193631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2440\\1656916536.py:15: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
      "  styled_cleaned_df = cleaned_df.style.applymap(highlight_needs, subset=['AI_Need_Summary'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Exported] Cleaned_Data/AI_Showcase_Cleaned_Export.xlsx with 3 Sheets — (Master_Combined_List, Cleaned_AI_Needs, Styled_AI_Needs)\n"
     ]
    }
   ],
   "source": [
    "from pandas import ExcelWriter\n",
    "# --- Export All DataFrames to One Excel File with Multiple Sheets ---\n",
    "output_path = 'Cleaned_Data/AI_Showcase_Cleaned_Export.xlsx'\n",
    "\n",
    "# Prepare styled DataFrame with colors for AI_Need_Summary\n",
    "def highlight_needs(val):\n",
    "    if 'Automation Service' in val:\n",
    "        return 'background-color: #B6E2D3'\n",
    "    elif 'Team Training' in val:\n",
    "        return 'background-color: #FFD699'\n",
    "    elif 'Personal Course' in val:\n",
    "        return 'background-color: #FF9999'\n",
    "    return ''\n",
    "\n",
    "styled_cleaned_df = cleaned_df.style.applymap(highlight_needs, subset=['AI_Need_Summary'])\n",
    "\n",
    "# --- Export using ExcelWriter ---\n",
    "with ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    # Sheet 1: Master Combined List (Raw)\n",
    "    combined_df.to_excel(writer, sheet_name='Master_Combined_List', index=False)\n",
    "\n",
    "    # Sheet 2: Cleaned & Summarized Data\n",
    "    cleaned_df.to_excel(writer, sheet_name='Cleaned_AI_Needs', index=False)\n",
    "\n",
    "    # Sheet 3: Styled AI Needs Summary\n",
    "    styled_cleaned_df.to_excel(writer, sheet_name='Styled_AI_Needs', index=False)\n",
    "\n",
    "print(f\"[Exported] {output_path} with 3 Sheets — (Master_Combined_List, Cleaned_AI_Needs, Styled_AI_Needs)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
